# AI RAG Enterprise Knowledge Base

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green.svg)](https://fastapi.tiangolo.com/)
[![LangChain](https://img.shields.io/badge/LangChain-0.1-orange.svg)](https://langchain.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A production-grade **Retrieval-Augmented Generation (RAG)** system for enterprise knowledge management. Ingest documents, build semantic indexes, and query your knowledge base using natural language.

## ğŸš€ Features

- **Multi-format Document Ingestion**: PDF, DOCX, TXT, Markdown, HTML
- **Semantic Search**: ChromaDB vector store with sentence-transformers embeddings
- **LLM Integration**: OpenAI GPT-4, Anthropic Claude, or local models via Ollama
- **REST API**: FastAPI with OpenAPI documentation
- **Authentication**: JWT-based auth with role-based access control
- **Async Processing**: Background document processing with Celery
- **Observability**: Structured logging, Prometheus metrics, health checks

## ğŸ“ Project Structure

```
ai-rag-enterprise-knowledge-base/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                 # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ documents.py     # Document upload/management
â”‚   â”‚   â”œâ”€â”€ query.py         # RAG query endpoints
â”‚   â”‚   â””â”€â”€ auth.py          # Authentication
â”‚   â”œâ”€â”€ core/                # Core RAG logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embeddings.py    # Embedding models
â”‚   â”‚   â”œâ”€â”€ vectorstore.py   # ChromaDB integration
â”‚   â”‚   â”œâ”€â”€ retriever.py     # Document retrieval
â”‚   â”‚   â”œâ”€â”€ llm.py           # LLM abstraction
â”‚   â”‚   â””â”€â”€ chains.py        # LangChain RAG chains
â”‚   â”œâ”€â”€ ingestion/           # Document processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loaders.py       # File loaders
â”‚   â”‚   â”œâ”€â”€ chunkers.py      # Text splitting
â”‚   â”‚   â””â”€â”€ pipeline.py      # Ingestion pipeline
â”‚   â”œâ”€â”€ models/              # Pydantic models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ documents.py
â”‚   â”‚   â””â”€â”€ queries.py
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â””â”€â”€ main.py              # Application entrypoint
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_api/
â”‚   â”œâ”€â”€ test_core/
â”‚   â””â”€â”€ test_ingestion/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/Shivay00001/ai-rag-enterprise-knowledge-base.git
cd ai-rag-enterprise-knowledge-base

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set environment variables
cp .env.example .env
# Edit .env with your API keys

# Run the application
uvicorn src.main:app --reload
```

## ğŸ³ Docker

```bash
docker-compose up -d
```

## ğŸ“– API Usage

### Upload Document

```bash
curl -X POST "http://localhost:8000/api/v1/documents" \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@knowledge_base.pdf"
```

### Query Knowledge Base

```bash
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is our refund policy?", "top_k": 5}'
```

## âš™ï¸ Configuration

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key | - |
| `EMBEDDING_MODEL` | Embedding model name | `all-MiniLM-L6-v2` |
| `LLM_MODEL` | LLM model name | `gpt-4-turbo-preview` |
| `CHROMA_PERSIST_DIR` | ChromaDB storage path | `./data/chroma` |
| `CHUNK_SIZE` | Document chunk size | `1000` |
| `CHUNK_OVERLAP` | Chunk overlap | `200` |

## ğŸ§ª Testing

```bash
pytest tests/ -v --cov=src
```

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.
